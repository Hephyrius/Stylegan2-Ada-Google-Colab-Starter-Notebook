{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stylegan2-Ada-Colab-Starter",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hephyrius/Stylegan2-Ada-Google-Colab-Starter-Notebook/blob/main/Stylegan2_Ada_Colab_Starter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2f3x92zKLlyE"
      },
      "source": [
        "Mount your drive! This is for two things\n",
        "\n",
        "1) Saving results and checkpoints for later reuse\n",
        "2) loading your own custom datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8VnyjDhiBQY"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTsXnA7vLxK-"
      },
      "source": [
        "Extract your own custom data from google drive and store it in the folder \"my_data\". "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-Etf334QxqM"
      },
      "source": [
        "import zipfile\n",
        "path = \"/content/drive/My Drive/path/to/zip/\"\n",
        "dataset = \"my_data.zip\"\n",
        "local_path = \"my_data/\"\n",
        "file_name = path + dataset\n",
        "with zipfile.ZipFile(file_name, 'r') as zip:\n",
        "   #zip.printdir()\n",
        "   print('Extracting all the files now...') \n",
        "   zip.extractall(local_path) \n",
        "   print('Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCp-pnotL8R0"
      },
      "source": [
        "Pull the latest version of stylegan2-ada from github, Use the right version of TF And make sure we can talk to the colab gpu\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzDuIoMcqfBT"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "# Download the code\n",
        "!git clone https://github.com/NVlabs/stylegan2-ada.git\n",
        "%cd stylegan2\n",
        "!nvcc test_nvcc.cu -o test_nvcc -run\n",
        "\n",
        "print('Tensorflow version: {}'.format(tf.__version__) )\n",
        "!nvidia-smi -L\n",
        "print('GPU Identified at: {}'.format(tf.test.gpu_device_name()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umKaTRK4dlL7"
      },
      "source": [
        "%cd .."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAgPsEMjMVeE"
      },
      "source": [
        "I'm assuming you don't have any model you'd like to resume from. So we will pull one of the models from the stylegan2 ada paper. Specifically the 256x256 version of FFHQ. \n",
        "\n",
        "Major note - ALWAYS transfer learn when you can. Convergence is so much faster!!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNw6T-DZJjHq"
      },
      "source": [
        "!wget https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/transfer-learning-source-nets/ffhq-res256-mirror-paper256-noaug.pkl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0W9Tyn2NBjG"
      },
      "source": [
        "Delete anything in our dataset that isn't actually an image\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWMPNER11Z_A"
      },
      "source": [
        "import os\n",
        "from fastai.vision import verify_images\n",
        "verify_images(local_path, delete=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBbkV2Fq_CUy"
      },
      "source": [
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "from os import mkdir\n",
        "import shutil"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnu0I2dVke1o"
      },
      "source": [
        "for p in [\"datasets/\", 'datasets/custom']:\n",
        "  try:\n",
        "    os.mkdir(p)\n",
        "  except:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4nNOUx6LbU8"
      },
      "source": [
        "The below cell creates a TF records file which stylegan2 ada needs to train successfully!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mrd-UJH5_pXK"
      },
      "source": [
        "%cd /content/stylegan2-ada/\n",
        "!python dataset_tool.py create_from_images /content/datasets/custom/ /content/my_data/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdnBhgrwblt3"
      },
      "source": [
        "%cd /content/stylegan2-ada/training"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhwL9nVrLI-2"
      },
      "source": [
        "Some minor changes to the training loop. Mainly creating a checkpoint every 10,000 images. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-F8bZxFECqpu"
      },
      "source": [
        "%%writefile training_loop.py\n",
        "ï»¿# Copyright (c) 2020, NVIDIA CORPORATION.  All rights reserved.\n",
        "#\n",
        "# NVIDIA CORPORATION and its licensors retain all intellectual property\n",
        "# and proprietary rights in and to this software, related documentation\n",
        "# and any modifications thereto.  Any use, reproduction, disclosure or\n",
        "# distribution of this software and related documentation without an express\n",
        "# license agreement from NVIDIA CORPORATION is strictly prohibited.\n",
        "\n",
        "\"\"\"Main training loop.\"\"\"\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "import time\n",
        "import PIL.Image\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import dnnlib\n",
        "import dnnlib.tflib as tflib\n",
        "from dnnlib.tflib.autosummary import autosummary\n",
        "\n",
        "from training import dataset\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "# Select size and contents of the image snapshot grids that are exported\n",
        "# periodically during training.\n",
        "\n",
        "def setup_snapshot_image_grid(training_set):\n",
        "    gw = np.clip(7680 // training_set.shape[2], 7, 32)\n",
        "    gh = np.clip(4320 // training_set.shape[1], 4, 32)\n",
        "\n",
        "    # Unconditional.\n",
        "    if training_set.label_size == 0:\n",
        "        reals, labels = training_set.get_minibatch_np(gw * gh)\n",
        "        return (gw, gh), reals, labels\n",
        "\n",
        "    # Row per class.\n",
        "    cw, ch = (gw, 1)\n",
        "    nw = (gw - 1) // cw + 1\n",
        "    nh = (gh - 1) // ch + 1\n",
        "\n",
        "    # Collect images.\n",
        "    blocks = [[] for _i in range(nw * nh)]\n",
        "    for _iter in range(1000000):\n",
        "        real, label = training_set.get_minibatch_np(1)\n",
        "        idx = np.argmax(label[0])\n",
        "        while idx < len(blocks) and len(blocks[idx]) >= cw * ch:\n",
        "            idx += training_set.label_size\n",
        "        if idx < len(blocks):\n",
        "            blocks[idx].append((real, label))\n",
        "            if all(len(block) >= cw * ch for block in blocks):\n",
        "                break\n",
        "\n",
        "    # Layout grid.\n",
        "    reals = np.zeros([gw * gh] + training_set.shape, dtype=training_set.dtype)\n",
        "    labels = np.zeros([gw * gh, training_set.label_size], dtype=training_set.label_dtype)\n",
        "    for i, block in enumerate(blocks):\n",
        "        for j, (real, label) in enumerate(block):\n",
        "            x = (i %  nw) * cw + j %  cw\n",
        "            y = (i // nw) * ch + j // cw\n",
        "            if x < gw and y < gh:\n",
        "                reals[x + y * gw] = real[0]\n",
        "                labels[x + y * gw] = label[0]\n",
        "    return (gw, gh), reals, labels\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "\n",
        "def save_image_grid(images, filename, drange, grid_size):\n",
        "    lo, hi = drange\n",
        "    gw, gh = grid_size\n",
        "    images = np.asarray(images, dtype=np.float32)\n",
        "    images = (images - lo) * (255 / (hi - lo))\n",
        "    images = np.rint(images).clip(0, 255).astype(np.uint8)\n",
        "    _N, C, H, W = images.shape\n",
        "    images = images.reshape(gh, gw, C, H, W)\n",
        "    images = images.transpose(0, 3, 1, 4, 2)\n",
        "    images = images.reshape(gh * H, gw * W, C)\n",
        "    PIL.Image.fromarray(images, {3: 'RGB', 1: 'L'}[C]).save(filename)\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "# Main training script.\n",
        "\n",
        "def training_loop(\n",
        "    run_dir                 = '.',      # Output directory.\n",
        "    G_args                  = {},       # Options for generator network.\n",
        "    D_args                  = {},       # Options for discriminator network.\n",
        "    G_opt_args              = {},       # Options for generator optimizer.\n",
        "    D_opt_args              = {},       # Options for discriminator optimizer.\n",
        "    loss_args               = {},       # Options for loss function.\n",
        "    train_dataset_args      = {},       # Options for dataset to train with.\n",
        "    metric_dataset_args     = {},       # Options for dataset to evaluate metrics against.\n",
        "    augment_args            = {},       # Options for adaptive augmentations.\n",
        "    metric_arg_list         = [],       # Metrics to evaluate during training.\n",
        "    num_gpus                = 1,        # Number of GPUs to use.\n",
        "    minibatch_size          = 32,       # Global minibatch size.\n",
        "    minibatch_gpu           = 4,        # Number of samples processed at a time by one GPU.\n",
        "    G_smoothing_kimg        = 10,       # Half-life of the exponential moving average (EMA) of generator weights.\n",
        "    G_smoothing_rampup      = None,     # EMA ramp-up coefficient.\n",
        "    minibatch_repeats       = 4,        # Number of minibatches to run in the inner loop.\n",
        "    lazy_regularization     = True,     # Perform regularization as a separate training step?\n",
        "    G_reg_interval          = 4,        # How often the perform regularization for G? Ignored if lazy_regularization=False.\n",
        "    D_reg_interval          = 16,       # How often the perform regularization for D? Ignored if lazy_regularization=False.\n",
        "    total_kimg              = 25000,    # Total length of the training, measured in thousands of real images.\n",
        "    kimg_per_tick           = 10,        # Progress snapshot interval.\n",
        "    image_snapshot_ticks    = 1,       # How often to save image snapshots? None = only save 'reals.png' and 'fakes-init.png'.\n",
        "    network_snapshot_ticks  = 1,       # How often to save network snapshots? None = only save 'networks-final.pkl'.\n",
        "    resume_pkl              = None,     # Network pickle to resume training from, None = train from scratch.\n",
        "    resume_kimg             = 15000,      # Assumed training progress at the beginning. Affects reporting and training schedule.\n",
        "    resume_time             = 0.0,      # Assumed wallclock time at the beginning. Affects reporting.\n",
        "    abort_fn                = None,     # Callback function for determining whether to abort training.\n",
        "    progress_fn             = None,     # Callback function for updating training progress.\n",
        "):\n",
        "    assert minibatch_size % (num_gpus * minibatch_gpu) == 0\n",
        "    start_time = time.time()\n",
        "\n",
        "    print('Loading training set...')\n",
        "    training_set = dataset.load_dataset(**train_dataset_args)\n",
        "    print('Image shape:', np.int32(training_set.shape).tolist())\n",
        "    print('Label shape:', [training_set.label_size])\n",
        "    print()\n",
        "\n",
        "    print('Constructing networks...')\n",
        "    with tf.device('/gpu:0'):\n",
        "        G = tflib.Network('G', num_channels=training_set.shape[0], resolution=training_set.shape[1], label_size=training_set.label_size, **G_args)\n",
        "        D = tflib.Network('D', num_channels=training_set.shape[0], resolution=training_set.shape[1], label_size=training_set.label_size, **D_args)\n",
        "        Gs = G.clone('Gs')\n",
        "        if resume_pkl is not None:\n",
        "            print(f'Resuming from \"{resume_pkl}\"')\n",
        "            with dnnlib.util.open_url(resume_pkl) as f:\n",
        "                rG, rD, rGs = pickle.load(f)\n",
        "            G.copy_vars_from(rG)\n",
        "            D.copy_vars_from(rD)\n",
        "            Gs.copy_vars_from(rGs)\n",
        "    G.print_layers()\n",
        "    D.print_layers()\n",
        "\n",
        "    print('Exporting sample images...')\n",
        "    grid_size, grid_reals, grid_labels = setup_snapshot_image_grid(training_set)\n",
        "    save_image_grid(grid_reals, os.path.join(run_dir, 'reals.png'), drange=[0,255], grid_size=grid_size)\n",
        "    grid_latents = np.random.randn(np.prod(grid_size), *G.input_shape[1:])\n",
        "    grid_fakes = Gs.run(grid_latents, grid_labels, is_validation=True, minibatch_size=minibatch_gpu)\n",
        "    save_image_grid(grid_fakes, os.path.join(run_dir, 'fakes_init.png'), drange=[-1,1], grid_size=grid_size)\n",
        "\n",
        "    print(f'Replicating networks across {num_gpus} GPUs...')\n",
        "    G_gpus = [G]\n",
        "    D_gpus = [D]\n",
        "    for gpu in range(1, num_gpus):\n",
        "        with tf.device(f'/gpu:{gpu}'):\n",
        "            G_gpus.append(G.clone(f'{G.name}_gpu{gpu}'))\n",
        "            D_gpus.append(D.clone(f'{D.name}_gpu{gpu}'))\n",
        "\n",
        "    print('Initializing augmentations...')\n",
        "    aug = None\n",
        "    if augment_args.get('class_name', None) is not None:\n",
        "        aug = dnnlib.util.construct_class_by_name(**augment_args)\n",
        "        aug.init_validation_set(D_gpus=D_gpus, training_set=training_set)\n",
        "\n",
        "    print('Setting up optimizers...')\n",
        "    G_opt_args = dict(G_opt_args)\n",
        "    D_opt_args = dict(D_opt_args)\n",
        "    for args, reg_interval in [(G_opt_args, G_reg_interval), (D_opt_args, D_reg_interval)]:\n",
        "        args['minibatch_multiplier'] = minibatch_size // num_gpus // minibatch_gpu\n",
        "        if lazy_regularization:\n",
        "            mb_ratio = reg_interval / (reg_interval + 1)\n",
        "            args['learning_rate'] *= mb_ratio\n",
        "            if 'beta1' in args: args['beta1'] **= mb_ratio\n",
        "            if 'beta2' in args: args['beta2'] **= mb_ratio\n",
        "    G_opt = tflib.Optimizer(name='TrainG', **G_opt_args)\n",
        "    D_opt = tflib.Optimizer(name='TrainD', **D_opt_args)\n",
        "    G_reg_opt = tflib.Optimizer(name='RegG', share=G_opt, **G_opt_args)\n",
        "    D_reg_opt = tflib.Optimizer(name='RegD', share=D_opt, **D_opt_args)\n",
        "\n",
        "    print('Constructing training graph...')\n",
        "    data_fetch_ops = []\n",
        "    training_set.configure(minibatch_gpu)\n",
        "    for gpu, (G_gpu, D_gpu) in enumerate(zip(G_gpus, D_gpus)):\n",
        "        with tf.name_scope(f'Train_gpu{gpu}'), tf.device(f'/gpu:{gpu}'):\n",
        "\n",
        "            # Fetch training data via temporary variables.\n",
        "            with tf.name_scope('DataFetch'):\n",
        "                real_images_var = tf.Variable(name='images', trainable=False, initial_value=tf.zeros([minibatch_gpu] + training_set.shape))\n",
        "                real_labels_var = tf.Variable(name='labels', trainable=False, initial_value=tf.zeros([minibatch_gpu, training_set.label_size]))\n",
        "                real_images_write, real_labels_write = training_set.get_minibatch_tf()\n",
        "                real_images_write = tflib.convert_images_from_uint8(real_images_write)\n",
        "                data_fetch_ops += [tf.assign(real_images_var, real_images_write)]\n",
        "                data_fetch_ops += [tf.assign(real_labels_var, real_labels_write)]\n",
        "\n",
        "            # Evaluate loss function and register gradients.\n",
        "            fake_labels = training_set.get_random_labels_tf(minibatch_gpu)\n",
        "            terms = dnnlib.util.call_func_by_name(G=G_gpu, D=D_gpu, aug=aug, fake_labels=fake_labels, real_images=real_images_var, real_labels=real_labels_var, **loss_args)\n",
        "            if lazy_regularization:\n",
        "                if terms.G_reg is not None: G_reg_opt.register_gradients(tf.reduce_mean(terms.G_reg * G_reg_interval), G_gpu.trainables)\n",
        "                if terms.D_reg is not None: D_reg_opt.register_gradients(tf.reduce_mean(terms.D_reg * D_reg_interval), D_gpu.trainables)\n",
        "            else:\n",
        "                if terms.G_reg is not None: terms.G_loss += terms.G_reg\n",
        "                if terms.D_reg is not None: terms.D_loss += terms.D_reg\n",
        "            G_opt.register_gradients(tf.reduce_mean(terms.G_loss), G_gpu.trainables)\n",
        "            D_opt.register_gradients(tf.reduce_mean(terms.D_loss), D_gpu.trainables)\n",
        "\n",
        "    print('Finalizing training ops...')\n",
        "    data_fetch_op = tf.group(*data_fetch_ops)\n",
        "    G_train_op = G_opt.apply_updates()\n",
        "    D_train_op = D_opt.apply_updates()\n",
        "    G_reg_op = G_reg_opt.apply_updates(allow_no_op=True)\n",
        "    D_reg_op = D_reg_opt.apply_updates(allow_no_op=True)\n",
        "    Gs_beta_in = tf.placeholder(tf.float32, name='Gs_beta_in', shape=[])\n",
        "    Gs_update_op = Gs.setup_as_moving_average_of(G, beta=Gs_beta_in)\n",
        "    tflib.init_uninitialized_vars()\n",
        "    with tf.device('/gpu:0'):\n",
        "        peak_gpu_mem_op = tf.contrib.memory_stats.MaxBytesInUse()\n",
        "\n",
        "    print('Initializing metrics...')\n",
        "    summary_log = tf.summary.FileWriter(run_dir)\n",
        "    metrics = []\n",
        "    for args in metric_arg_list:\n",
        "        metric = dnnlib.util.construct_class_by_name(**args)\n",
        "        metric.configure(dataset_args=metric_dataset_args, run_dir=run_dir)\n",
        "        metrics.append(metric)\n",
        "\n",
        "    print(f'Training for {total_kimg} kimg...')\n",
        "    print()\n",
        "    if progress_fn is not None:\n",
        "        progress_fn(0, total_kimg)\n",
        "    tick_start_time = time.time()\n",
        "    maintenance_time = tick_start_time - start_time\n",
        "    cur_nimg = 0\n",
        "    cur_tick = -1\n",
        "    tick_start_nimg = cur_nimg\n",
        "    running_mb_counter = 0\n",
        "\n",
        "    done = False\n",
        "    while not done:\n",
        "\n",
        "        # Compute EMA decay parameter.\n",
        "        Gs_nimg = G_smoothing_kimg * 1000.0\n",
        "        if G_smoothing_rampup is not None:\n",
        "            Gs_nimg = min(Gs_nimg, cur_nimg * G_smoothing_rampup)\n",
        "        Gs_beta = 0.5 ** (minibatch_size / max(Gs_nimg, 1e-8))\n",
        "\n",
        "        # Run training ops.\n",
        "        for _repeat_idx in range(minibatch_repeats):\n",
        "            rounds = range(0, minibatch_size, minibatch_gpu * num_gpus)\n",
        "            run_G_reg = (lazy_regularization and running_mb_counter % G_reg_interval == 0)\n",
        "            run_D_reg = (lazy_regularization and running_mb_counter % D_reg_interval == 0)\n",
        "            cur_nimg += minibatch_size\n",
        "            running_mb_counter += 1\n",
        "\n",
        "            # Fast path without gradient accumulation.\n",
        "            if len(rounds) == 1:\n",
        "                tflib.run([G_train_op, data_fetch_op])\n",
        "                if run_G_reg:\n",
        "                    tflib.run(G_reg_op)\n",
        "                tflib.run([D_train_op, Gs_update_op], {Gs_beta_in: Gs_beta})\n",
        "                if run_D_reg:\n",
        "                    tflib.run(D_reg_op)\n",
        "\n",
        "            # Slow path with gradient accumulation.\n",
        "            else:\n",
        "                for _round in rounds:\n",
        "                    tflib.run(G_train_op)\n",
        "                    if run_G_reg:\n",
        "                        tflib.run(G_reg_op)\n",
        "                tflib.run(Gs_update_op, {Gs_beta_in: Gs_beta})\n",
        "                for _round in rounds:\n",
        "                    tflib.run(data_fetch_op)\n",
        "                    tflib.run(D_train_op)\n",
        "                    if run_D_reg:\n",
        "                        tflib.run(D_reg_op)\n",
        "\n",
        "            # Run validation.\n",
        "            if aug is not None:\n",
        "                aug.run_validation(minibatch_size=minibatch_size)\n",
        "\n",
        "        # Tune augmentation parameters.\n",
        "        if aug is not None:\n",
        "            aug.tune(minibatch_size * minibatch_repeats)\n",
        "\n",
        "        # Perform maintenance tasks once per tick.\n",
        "        done = (cur_nimg >= total_kimg * 1000) or (abort_fn is not None and abort_fn())\n",
        "        if done or cur_tick < 0 or cur_nimg >= tick_start_nimg + kimg_per_tick * 1000:\n",
        "            cur_tick += 1\n",
        "            tick_kimg = (cur_nimg - tick_start_nimg) / 1000.0\n",
        "            tick_start_nimg = cur_nimg\n",
        "            tick_end_time = time.time()\n",
        "            total_time = tick_end_time - start_time\n",
        "            tick_time = tick_end_time - tick_start_time\n",
        "\n",
        "            # Report progress.\n",
        "            print(' '.join([\n",
        "                f\"tick {autosummary('Progress/tick', cur_tick):<5d}\",\n",
        "                f\"kimg {autosummary('Progress/kimg', cur_nimg / 1000.0):<8.1f}\",\n",
        "                f\"time {dnnlib.util.format_time(autosummary('Timing/total_sec', total_time)):<12s}\",\n",
        "                f\"sec/tick {autosummary('Timing/sec_per_tick', tick_time):<7.1f}\",\n",
        "                f\"sec/kimg {autosummary('Timing/sec_per_kimg', tick_time / tick_kimg):<7.2f}\",\n",
        "                f\"maintenance {autosummary('Timing/maintenance_sec', maintenance_time):<6.1f}\",\n",
        "                f\"gpumem {autosummary('Resources/peak_gpu_mem_gb', peak_gpu_mem_op.eval() / 2**30):<5.1f}\",\n",
        "                f\"augment {autosummary('Progress/augment', aug.strength if aug is not None else 0):.3f}\",\n",
        "            ]))\n",
        "            autosummary('Timing/total_hours', total_time / (60.0 * 60.0))\n",
        "            autosummary('Timing/total_days', total_time / (24.0 * 60.0 * 60.0))\n",
        "            if progress_fn is not None:\n",
        "                progress_fn(cur_nimg // 1000, total_kimg)\n",
        "\n",
        "            # Save snapshots.\n",
        "            if image_snapshot_ticks is not None and (done or cur_tick % image_snapshot_ticks == 0):\n",
        "                grid_fakes = Gs.run(grid_latents, grid_labels, is_validation=True, minibatch_size=minibatch_gpu)\n",
        "                save_image_grid(grid_fakes, os.path.join(run_dir, f'fakes{cur_nimg // 1000:06d}.png'), drange=[-1,1], grid_size=grid_size)\n",
        "\n",
        "            if network_snapshot_ticks is not None and (done or cur_tick % network_snapshot_ticks == 0):\n",
        "                pkl = os.path.join(run_dir, f'network-snapshot-{cur_nimg // 1000:06d}.pkl')\n",
        "                with open(pkl, 'wb') as f:\n",
        "                    pickle.dump((G, D, Gs), f)\n",
        "                if len(metrics):\n",
        "                    print('Evaluating metrics...')\n",
        "                    for metric in metrics:\n",
        "                        metric.run(pkl, num_gpus=num_gpus)\n",
        "\n",
        "            # Update summaries.\n",
        "            for metric in metrics:\n",
        "                metric.update_autosummaries()\n",
        "            tflib.autosummary.save_summaries(summary_log, cur_nimg)\n",
        "            tick_start_time = time.time()\n",
        "            maintenance_time = tick_start_time - tick_end_time\n",
        "\n",
        "    print()\n",
        "    print('Exiting...')\n",
        "    summary_log.close()\n",
        "    training_set.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8qcPk0sPMln"
      },
      "source": [
        "%cd .."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUES7ATGIWCI"
      },
      "source": [
        "## Start the training of the network.\n",
        "\n",
        "key things to change here:\n",
        "\n",
        "1) Outdir - if you want to save grids and weights to a different folder on your google drive.\n",
        "\n",
        "2) Resume - change this to your own pickle if you want to carry on trainning a model after a timeout\n",
        "\n",
        "3) Cfg - change this if you want to play with some of the other configs on offer. I'd recommend using the \"stylegan2\" config as this is close to the original experience + the benefits of augmentation :)\n",
        "\n",
        "do not change:\n",
        "\n",
        "1) Metrics - enabling metrics slows down training a ton! if you want to test models do it in a stand alone manner!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPRz35T4QVRu"
      },
      "source": [
        "# Copyright (c) 2020, NVIDIA CORPORATION.  All rights reserved.\n",
        "#\n",
        "# NVIDIA CORPORATION and its licensors retain all intellectual property\n",
        "# and proprietary rights in and to this software, related documentation\n",
        "# and any modifications thereto.  Any use, reproduction, disclosure or\n",
        "# distribution of this software and related documentation without an express\n",
        "# license agreement from NVIDIA CORPORATION is strictly prohibited.\n",
        "\n",
        "\"\"\"Train a GAN using the techniques described in the paper\n",
        "\"Training Generative Adversarial Networks with Limited Data\".\"\"\"\n",
        "\n",
        "import os\n",
        "import argparse\n",
        "import json\n",
        "import re\n",
        "import tensorflow as tf\n",
        "import dnnlib\n",
        "import dnnlib.tflib as tflib\n",
        "\n",
        "from training import training_loop\n",
        "from training import dataset\n",
        "from metrics import metric_defaults\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "\n",
        "class UserError(Exception):\n",
        "    pass\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "\n",
        "def setup_training_options():\n",
        "\n",
        "###########################################################################################################################\n",
        "#                                                 EDIT THESE!                                                             #\n",
        "###########################################################################################################################\n",
        "    train_params = DotMap()\n",
        "    outdir = '/content/drive/My Drive/Colab Notebooks/styleganada-results/'\n",
        "    gpus = None # Number of GPUs: <int>, default = 1 gpu\n",
        "    snap = 1 # Snapshot interval: <int>, default = 50 ticks\n",
        "    seed = 1000\n",
        "    data = '/content/datasets/custom/'# Training dataset (required): <path>\n",
        "    res = None# Override dataset resolution: <int>, default = highest available\n",
        "    mirror =True# Augment dataset with x-flips: <bool>, default = False\n",
        "    metrics = None# List of metric names: [], ['fid50k_full'] (default), ...\n",
        "    metricdata = None# Metric dataset (optional): <path>\n",
        "    cfg = 'stylegan2'# Base config: 'auto' (default), 'stylegan2', 'paper256', 'paper512', 'paper1024', 'cifar', 'cifarbaseline'\n",
        "    gamma = None# Override R1 gamma: <float>, default = depends on cfg\n",
        "    kimg = 10000# Override training duration: <int>, default = depends on cfg\n",
        "    aug = 'ada' # Augmentation mode: 'ada' (default), 'noaug', 'fixed', 'adarv'\n",
        "    p = None# Specify p for 'fixed' (required): <float>\n",
        "    target = None # Override ADA target for 'ada' and 'adarv': <float>, default = depends on aug\n",
        "    augpipe = 'bgc'# Augmentation pipeline: 'blit', 'geom', 'color', 'filter', 'noise', 'cutout', 'bg', 'bgc' (default), ..., 'bgcfnc'\n",
        "    cmethod = None # Comparison method: 'nocmethod' (default), 'bcr', 'zcr', 'pagan', 'wgangp', 'auxrot', 'spectralnorm', 'shallowmap', 'adropout'\n",
        "    dcap = None # Multiplier for discriminator capacity: <float>, default = 1\n",
        "    augpipe = 'bgc'\n",
        "    resume = 'ffhq-res256-mirror-paper256-noaug.pkl'# Load previous network: 'noresume' (default), 'ffhq256', 'ffhq512', 'ffhq1024', 'celebahq256', 'lsundog256', <file>, <url>\n",
        "    freezed = None # Freeze-D: <int>, default = 0 discriminator layers\n",
        "\n",
        "\n",
        "###########################################################################################################################\n",
        "#                                                 End of Edit Section                                                     #\n",
        "###########################################################################################################################\n",
        "\n",
        "    tflib.init_tf({'rnd.np_random_seed': seed})\n",
        "\n",
        "    # Initialize dicts.\n",
        "    args = dnnlib.EasyDict()\n",
        "    args.G_args = dnnlib.EasyDict(func_name='training.networks.G_main')\n",
        "    args.D_args = dnnlib.EasyDict(func_name='training.networks.D_main')\n",
        "    args.G_opt_args = dnnlib.EasyDict(beta1=0.0, beta2=0.99)\n",
        "    args.D_opt_args = dnnlib.EasyDict(beta1=0.0, beta2=0.99)\n",
        "    args.loss_args = dnnlib.EasyDict(func_name='training.loss.stylegan2')\n",
        "    args.augment_args = dnnlib.EasyDict(class_name='training.augment.AdaptiveAugment')\n",
        "\n",
        "    # ---------------------------\n",
        "    # General options: gpus, snap\n",
        "    # ---------------------------\n",
        "\n",
        "    if gpus is None:\n",
        "        gpus = 1\n",
        "    assert isinstance(gpus, int)\n",
        "    if not (gpus >= 1 and gpus & (gpus - 1) == 0):\n",
        "        raise UserError('--gpus must be a power of two')\n",
        "    args.num_gpus = gpus\n",
        "\n",
        "    if snap is None:\n",
        "        snap = 50\n",
        "    assert isinstance(snap, int)\n",
        "    if snap < 1:\n",
        "        raise UserError('--snap must be at least 1')\n",
        "    args.image_snapshot_ticks = snap\n",
        "    args.network_snapshot_ticks = snap\n",
        "\n",
        "    # -----------------------------------\n",
        "    # Training dataset: data, res, mirror\n",
        "    # -----------------------------------\n",
        "\n",
        "    assert data is not None\n",
        "    assert isinstance(data, str)\n",
        "    data_name = os.path.basename(os.path.abspath(data))\n",
        "    if not os.path.isdir(data) or len(data_name) == 0:\n",
        "        raise UserError('--data must point to a directory containing *.tfrecords')\n",
        "    desc = data_name\n",
        "\n",
        "    with tf.Graph().as_default(), tflib.create_session().as_default(): # pylint: disable=not-context-manager\n",
        "        args.train_dataset_args = dnnlib.EasyDict(path=data, max_label_size='full')\n",
        "        dataset_obj = dataset.load_dataset(**args.train_dataset_args) # try to load the data and see what comes out\n",
        "        args.train_dataset_args.resolution = dataset_obj.shape[-1] # be explicit about resolution\n",
        "        args.train_dataset_args.max_label_size = dataset_obj.label_size # be explicit about label size\n",
        "        validation_set_available = dataset_obj.has_validation_set\n",
        "        dataset_obj.close()\n",
        "        dataset_obj = None\n",
        "\n",
        "    if res is None:\n",
        "        res = args.train_dataset_args.resolution\n",
        "    else:\n",
        "        assert isinstance(res, int)\n",
        "        if not (res >= 4 and res & (res - 1) == 0):\n",
        "            raise UserError('--res must be a power of two and at least 4')\n",
        "        if res > args.train_dataset_args.resolution:\n",
        "            raise UserError(f'--res cannot exceed maximum available resolution in the dataset ({args.train_dataset_args.resolution})')\n",
        "        desc += f'-res{res:d}'\n",
        "    args.train_dataset_args.resolution = res\n",
        "\n",
        "    if mirror is None:\n",
        "        mirror = False\n",
        "    else:\n",
        "        assert isinstance(mirror, bool)\n",
        "        if mirror:\n",
        "            desc += '-mirror'\n",
        "    args.train_dataset_args.mirror_augment = mirror\n",
        "\n",
        "    # ----------------------------\n",
        "    # Metrics: metrics, metricdata\n",
        "    # ----------------------------\n",
        "\n",
        "    if metrics is None:\n",
        "        metrics = ['fid50k_full']\n",
        "    assert isinstance(metrics, list)\n",
        "    assert all(isinstance(metric, str) for metric in metrics)\n",
        "\n",
        "    args.metric_arg_list = []\n",
        "    for metric in metrics:\n",
        "        if metric not in metric_defaults.metric_defaults:\n",
        "            raise UserError('\\n'.join(['--metrics can only contain the following values:', 'none'] + list(metric_defaults.metric_defaults.keys())))\n",
        "        args.metric_arg_list.append(metric_defaults.metric_defaults[metric])\n",
        "\n",
        "    args.metric_dataset_args = dnnlib.EasyDict(args.train_dataset_args)\n",
        "    if metricdata is not None:\n",
        "        assert isinstance(metricdata, str)\n",
        "        if not os.path.isdir(metricdata):\n",
        "            raise UserError('--metricdata must point to a directory containing *.tfrecords')\n",
        "        args.metric_dataset_args.path = metricdata\n",
        "\n",
        "    # -----------------------------\n",
        "    # Base config: cfg, gamma, kimg\n",
        "    # -----------------------------\n",
        "\n",
        "    if cfg is None:\n",
        "        cfg = 'auto'\n",
        "    assert isinstance(cfg, str)\n",
        "    desc += f'-{cfg}'\n",
        "\n",
        "    cfg_specs = {\n",
        "        'auto':          dict(ref_gpus=-1, kimg=25000,  mb=-1, mbstd=-1, fmaps=-1,  lrate=-1,     gamma=-1,   ema=-1,  ramp=0.05, map=2), # populated dynamically based on 'gpus' and 'res'\n",
        "        'stylegan2':     dict(ref_gpus=8,  kimg=25000,  mb=32, mbstd=4,  fmaps=1,   lrate=0.002,  gamma=10,   ema=10,  ramp=None, map=8), # uses mixed-precision, unlike original StyleGAN2\n",
        "        'paper256':      dict(ref_gpus=8,  kimg=25000,  mb=64, mbstd=8,  fmaps=0.5, lrate=0.0025, gamma=1,    ema=20,  ramp=None, map=8),\n",
        "        'paper512':      dict(ref_gpus=8,  kimg=25000,  mb=64, mbstd=8,  fmaps=1,   lrate=0.0025, gamma=0.5,  ema=20,  ramp=None, map=8),\n",
        "        'paper1024':     dict(ref_gpus=8,  kimg=25000,  mb=32, mbstd=4,  fmaps=1,   lrate=0.002,  gamma=2,    ema=10,  ramp=None, map=8),\n",
        "        'cifar':         dict(ref_gpus=2,  kimg=100000, mb=64, mbstd=32, fmaps=0.5, lrate=0.0025, gamma=0.01, ema=500, ramp=0.05, map=2),\n",
        "        'cifarbaseline': dict(ref_gpus=2,  kimg=100000, mb=64, mbstd=32, fmaps=0.5, lrate=0.0025, gamma=0.01, ema=500, ramp=0.05, map=8),\n",
        "    }\n",
        "\n",
        "    assert cfg in cfg_specs\n",
        "    spec = dnnlib.EasyDict(cfg_specs[cfg])\n",
        "    if cfg == 'auto':\n",
        "        desc += f'{gpus:d}'\n",
        "        spec.ref_gpus = gpus\n",
        "        spec.mb = max(min(gpus * min(4096 // res, 32), 64), gpus) # keep gpu memory consumption at bay\n",
        "        spec.mbstd = min(spec.mb // gpus, 4) # other hyperparams behave more predictably if mbstd group size remains fixed\n",
        "        spec.fmaps = 1 if res >= 512 else 0.5\n",
        "        spec.lrate = 0.002 if res >= 1024 else 0.0025\n",
        "        spec.gamma = 0.0002 * (res ** 2) / spec.mb # heuristic formula\n",
        "        spec.ema = spec.mb * 10 / 32\n",
        "\n",
        "    args.total_kimg = spec.kimg\n",
        "    args.minibatch_size = spec.mb\n",
        "    args.minibatch_gpu = spec.mb // spec.ref_gpus\n",
        "    args.D_args.mbstd_group_size = spec.mbstd\n",
        "    args.G_args.fmap_base = args.D_args.fmap_base = int(spec.fmaps * 16384)\n",
        "    args.G_args.fmap_max = args.D_args.fmap_max = 512\n",
        "    args.G_opt_args.learning_rate = args.D_opt_args.learning_rate = spec.lrate\n",
        "    args.loss_args.r1_gamma = spec.gamma\n",
        "    args.G_smoothing_kimg = spec.ema\n",
        "    args.G_smoothing_rampup = spec.ramp\n",
        "    args.G_args.mapping_layers = spec.map\n",
        "    args.G_args.num_fp16_res = args.D_args.num_fp16_res = 4 # enable mixed-precision training\n",
        "    args.G_args.conv_clamp = args.D_args.conv_clamp = 256 # clamp activations to avoid float16 overflow\n",
        "\n",
        "    if cfg == 'cifar':\n",
        "        args.loss_args.pl_weight = 0 # disable path length regularization\n",
        "        args.G_args.style_mixing_prob = None # disable style mixing\n",
        "        args.D_args.architecture = 'orig' # disable residual skip connections\n",
        "\n",
        "    if gamma is not None:\n",
        "        assert isinstance(gamma, float)\n",
        "        if not gamma >= 0:\n",
        "            raise UserError('--gamma must be non-negative')\n",
        "        desc += f'-gamma{gamma:g}'\n",
        "        args.loss_args.r1_gamma = gamma\n",
        "\n",
        "    if kimg is not None:\n",
        "        assert isinstance(kimg, int)\n",
        "        if not kimg >= 1:\n",
        "            raise UserError('--kimg must be at least 1')\n",
        "        desc += f'-kimg{kimg:d}'\n",
        "        args.total_kimg = kimg\n",
        "\n",
        "    # ---------------------------------------------------\n",
        "    # Discriminator augmentation: aug, p, target, augpipe\n",
        "    # ---------------------------------------------------\n",
        "\n",
        "    if aug is None:\n",
        "        aug = 'ada'\n",
        "    else:\n",
        "        assert isinstance(aug, str)\n",
        "        desc += f'-{aug}'\n",
        "\n",
        "    if aug == 'ada':\n",
        "        args.augment_args.tune_heuristic = 'rt'\n",
        "        args.augment_args.tune_target = 0.6\n",
        "\n",
        "    elif aug == 'noaug':\n",
        "        pass\n",
        "\n",
        "    elif aug == 'fixed':\n",
        "        if p is None:\n",
        "            raise UserError(f'--aug={aug} requires specifying --p')\n",
        "\n",
        "    elif aug == 'adarv':\n",
        "        if not validation_set_available:\n",
        "            raise UserError(f'--aug={aug} requires separate validation set; please see \"python dataset_tool.py pack -h\"')\n",
        "        args.augment_args.tune_heuristic = 'rv'\n",
        "        args.augment_args.tune_target = 0.5\n",
        "\n",
        "    else:\n",
        "        raise UserError(f'--aug={aug} not supported')\n",
        "\n",
        "    if p is not None:\n",
        "        assert isinstance(p, float)\n",
        "        if aug != 'fixed':\n",
        "            raise UserError('--p can only be specified with --aug=fixed')\n",
        "        if not 0 <= p <= 1:\n",
        "            raise UserError('--p must be between 0 and 1')\n",
        "        desc += f'-p{p:g}'\n",
        "        args.augment_args.initial_strength = p\n",
        "\n",
        "    if target is not None:\n",
        "        assert isinstance(target, float)\n",
        "        if aug not in ['ada', 'adarv']:\n",
        "            raise UserError('--target can only be specified with --aug=ada or --aug=adarv')\n",
        "        if not 0 <= target <= 1:\n",
        "            raise UserError('--target must be between 0 and 1')\n",
        "        desc += f'-target{target:g}'\n",
        "        args.augment_args.tune_target = target\n",
        "\n",
        "    assert augpipe is None or isinstance(augpipe, str)\n",
        "    if augpipe is None:\n",
        "        augpipe = 'bgc'\n",
        "    else:\n",
        "        if aug == 'noaug':\n",
        "            raise UserError('--augpipe cannot be specified with --aug=noaug')\n",
        "        desc += f'-{augpipe}'\n",
        "\n",
        "    augpipe_specs = {\n",
        "        'blit':     dict(xflip=1, rotate90=1, xint=1),\n",
        "        'geom':     dict(scale=1, rotate=1, aniso=1, xfrac=1),\n",
        "        'color':    dict(brightness=1, contrast=1, lumaflip=1, hue=1, saturation=1),\n",
        "        'filter':   dict(imgfilter=1),\n",
        "        'noise':    dict(noise=1),\n",
        "        'cutout':   dict(cutout=1),\n",
        "        'bg':       dict(xflip=1, rotate90=1, xint=1, scale=1, rotate=1, aniso=1, xfrac=1),\n",
        "        'bgc':      dict(xflip=1, rotate90=1, xint=1, scale=1, rotate=1, aniso=1, xfrac=1, brightness=1, contrast=1, lumaflip=1, hue=1, saturation=1),\n",
        "        'bgcf':     dict(xflip=1, rotate90=1, xint=1, scale=1, rotate=1, aniso=1, xfrac=1, brightness=1, contrast=1, lumaflip=1, hue=1, saturation=1, imgfilter=1),\n",
        "        'bgcfn':    dict(xflip=1, rotate90=1, xint=1, scale=1, rotate=1, aniso=1, xfrac=1, brightness=1, contrast=1, lumaflip=1, hue=1, saturation=1, imgfilter=1, noise=1),\n",
        "        'bgcfnc':   dict(xflip=1, rotate90=1, xint=1, scale=1, rotate=1, aniso=1, xfrac=1, brightness=1, contrast=1, lumaflip=1, hue=1, saturation=1, imgfilter=1, noise=1, cutout=1),\n",
        "    }\n",
        "\n",
        "    assert augpipe in augpipe_specs\n",
        "    if aug != 'noaug':\n",
        "        args.augment_args.apply_func = 'training.augment.augment_pipeline'\n",
        "        args.augment_args.apply_args = augpipe_specs[augpipe]\n",
        "\n",
        "    # ---------------------------------\n",
        "    # Comparison methods: cmethod, dcap\n",
        "    # ---------------------------------\n",
        "\n",
        "    assert cmethod is None or isinstance(cmethod, str)\n",
        "    if cmethod is None:\n",
        "        cmethod = 'nocmethod'\n",
        "    else:\n",
        "        desc += f'-{cmethod}'\n",
        "\n",
        "    if cmethod == 'nocmethod':\n",
        "        pass\n",
        "\n",
        "    elif cmethod == 'bcr':\n",
        "        args.loss_args.func_name = 'training.loss.cmethods'\n",
        "        args.loss_args.bcr_real_weight = 10\n",
        "        args.loss_args.bcr_fake_weight = 10\n",
        "        args.loss_args.bcr_augment = dnnlib.EasyDict(func_name='training.augment.augment_pipeline', xint=1, xint_max=1/32)\n",
        "\n",
        "    elif cmethod == 'zcr':\n",
        "        args.loss_args.func_name = 'training.loss.cmethods'\n",
        "        args.loss_args.zcr_gen_weight = 0.02\n",
        "        args.loss_args.zcr_dis_weight = 0.2\n",
        "        args.G_args.num_fp16_res = args.D_args.num_fp16_res = 0 # disable mixed-precision training\n",
        "        args.G_args.conv_clamp = args.D_args.conv_clamp = None\n",
        "\n",
        "    elif cmethod == 'pagan':\n",
        "        if aug != 'noaug':\n",
        "            raise UserError(f'--cmethod={cmethod} is not compatible with discriminator augmentation; please specify --aug=noaug')\n",
        "        args.D_args.use_pagan = True\n",
        "        args.augment_args.tune_heuristic = 'rt' # enable ada heuristic\n",
        "        args.augment_args.pop('apply_func', None) # disable discriminator augmentation\n",
        "        args.augment_args.pop('apply_args', None)\n",
        "        args.augment_args.tune_target = 0.95\n",
        "\n",
        "    elif cmethod == 'wgangp':\n",
        "        if aug != 'noaug':\n",
        "            raise UserError(f'--cmethod={cmethod} is not compatible with discriminator augmentation; please specify --aug=noaug')\n",
        "        if gamma is not None:\n",
        "            raise UserError(f'--cmethod={cmethod} is not compatible with --gamma')\n",
        "        args.loss_args = dnnlib.EasyDict(func_name='training.loss.wgangp')\n",
        "        args.G_opt_args.learning_rate = args.D_opt_args.learning_rate = 0.001\n",
        "        args.G_args.num_fp16_res = args.D_args.num_fp16_res = 0 # disable mixed-precision training\n",
        "        args.G_args.conv_clamp = args.D_args.conv_clamp = None\n",
        "        args.lazy_regularization = False\n",
        "\n",
        "    elif cmethod == 'auxrot':\n",
        "        if args.train_dataset_args.max_label_size > 0:\n",
        "            raise UserError(f'--cmethod={cmethod} is not compatible with label conditioning; please specify a dataset without labels')\n",
        "        args.loss_args.func_name = 'training.loss.cmethods'\n",
        "        args.loss_args.auxrot_alpha = 10\n",
        "        args.loss_args.auxrot_beta = 5\n",
        "        args.D_args.score_max = 5 # prepare D to output 5 scalars per image instead of just 1\n",
        "\n",
        "    elif cmethod == 'spectralnorm':\n",
        "        args.D_args.use_spectral_norm = True\n",
        "\n",
        "    elif cmethod == 'shallowmap':\n",
        "        if args.G_args.mapping_layers == 2:\n",
        "            raise UserError(f'--cmethod={cmethod} is a no-op for --cfg={cfg}')\n",
        "        args.G_args.mapping_layers = 2\n",
        "\n",
        "    elif cmethod == 'adropout':\n",
        "        if aug != 'noaug':\n",
        "            raise UserError(f'--cmethod={cmethod} is not compatible with discriminator augmentation; please specify --aug=noaug')\n",
        "        args.D_args.adaptive_dropout = 1\n",
        "        args.augment_args.tune_heuristic = 'rt' # enable ada heuristic\n",
        "        args.augment_args.pop('apply_func', None) # disable discriminator augmentation\n",
        "        args.augment_args.pop('apply_args', None)\n",
        "        args.augment_args.tune_target = 0.6\n",
        "\n",
        "    else:\n",
        "        raise UserError(f'--cmethod={cmethod} not supported')\n",
        "\n",
        "    if dcap is not None:\n",
        "        assert isinstance(dcap, float)\n",
        "        if not dcap > 0:\n",
        "            raise UserError('--dcap must be positive')\n",
        "        desc += f'-dcap{dcap:g}'\n",
        "        args.D_args.fmap_base = max(int(args.D_args.fmap_base * dcap), 1)\n",
        "        args.D_args.fmap_max = max(int(args.D_args.fmap_max * dcap), 1)\n",
        "\n",
        "    # ----------------------------------\n",
        "    # Transfer learning: resume, freezed\n",
        "    # ----------------------------------\n",
        "\n",
        "    resume_specs = {\n",
        "        'ffhq256':      'https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/transfer-learning-source-nets/ffhq-res256-mirror-paper256-noaug.pkl',\n",
        "        'ffhq512':      'https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/transfer-learning-source-nets/ffhq-res512-mirror-stylegan2-noaug.pkl',\n",
        "        'ffhq1024':     'https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/transfer-learning-source-nets/ffhq-res1024-mirror-stylegan2-noaug.pkl',\n",
        "        'celebahq256':  'https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/transfer-learning-source-nets/celebahq-res256-mirror-paper256-kimg100000-ada-target0.5.pkl',\n",
        "        'lsundog256':   'https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/transfer-learning-source-nets/lsundog-res256-paper256-kimg100000-noaug.pkl',\n",
        "    }\n",
        "\n",
        "    assert resume is None or isinstance(resume, str)\n",
        "    if resume is None:\n",
        "        resume = 'noresume'\n",
        "    elif resume == 'noresume':\n",
        "        desc += '-noresume'\n",
        "    elif resume in resume_specs:\n",
        "        desc += f'-resume{resume}'\n",
        "        args.resume_pkl = resume_specs[resume] # predefined url\n",
        "    else:\n",
        "        desc += '-resumecustom'\n",
        "        args.resume_pkl = resume # custom path or url\n",
        "\n",
        "    if resume != 'noresume':\n",
        "        args.augment_args.tune_kimg = 100 # make ADA react faster at the beginning\n",
        "        args.G_smoothing_rampup = None # disable EMA rampup\n",
        "\n",
        "    if freezed is not None:\n",
        "        assert isinstance(freezed, int)\n",
        "        if not freezed >= 0:\n",
        "            raise UserError('--freezed must be non-negative')\n",
        "        desc += f'-freezed{freezed:d}'\n",
        "        args.D_args.freeze_layers = freezed\n",
        "\n",
        "    return desc, args, outdir\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "\n",
        "def run_training():\n",
        "\n",
        "    run_desc, training_options, outdir = setup_training_options()\n",
        "\n",
        "    # Pick output directory.\n",
        "    prev_run_dirs = []\n",
        "    if os.path.isdir(outdir):\n",
        "        prev_run_dirs = [x for x in os.listdir(outdir) if os.path.isdir(os.path.join(outdir, x))]\n",
        "    prev_run_ids = [re.match(r'^\\d+', x) for x in prev_run_dirs]\n",
        "    prev_run_ids = [int(x.group()) for x in prev_run_ids if x is not None]\n",
        "    cur_run_id = max(prev_run_ids, default=-1) + 1\n",
        "    training_options.run_dir = os.path.join(outdir, f'{cur_run_id:05d}-{run_desc}')\n",
        "    assert not os.path.exists(training_options.run_dir)\n",
        "\n",
        "    # Print options.\n",
        "    print()\n",
        "    print('Training options:')\n",
        "    print(json.dumps(training_options, indent=2))\n",
        "    print()\n",
        "    print(f'Output directory:  {training_options.run_dir}')\n",
        "    print(f'Training data:     {training_options.train_dataset_args.path}')\n",
        "    print(f'Training length:   {training_options.total_kimg} kimg')\n",
        "    print(f'Resolution:        {training_options.train_dataset_args.resolution}')\n",
        "    print(f'Number of GPUs:    {training_options.num_gpus}')\n",
        "    print()\n",
        "\n",
        "    # Kick off training.\n",
        "    print('Creating output directory...')\n",
        "    os.makedirs(training_options.run_dir)\n",
        "    with open(os.path.join(training_options.run_dir, 'training_options.json'), 'wt') as f:\n",
        "        json.dump(training_options, f, indent=2)\n",
        "    with dnnlib.util.Logger(os.path.join(training_options.run_dir, 'log.txt')):\n",
        "        training_loop.training_loop(**training_options)\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "\n",
        "def _str_to_bool(v):\n",
        "    if isinstance(v, bool):\n",
        "        return v\n",
        "    if v.lower() in ('yes', 'true', 't', 'y', '1'):\n",
        "        return True\n",
        "    if v.lower() in ('no', 'false', 'f', 'n', '0'):\n",
        "        return False\n",
        "    raise argparse.ArgumentTypeError('Boolean value expected.')\n",
        "\n",
        "def _parse_comma_sep(s):\n",
        "    if s is None or s.lower() == 'none' or s == '':\n",
        "        return []\n",
        "    return s.split(',')\n",
        "\n",
        "def main():\n",
        "    run_training()\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "#----------------------------------------------------------------------------"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}